# CS50

## Review with Questions

1. 請解釋`linear search`和`binary search`的原理及其時間複雜度(Big *O*)。 [答案](#Linear search, binary search)
2. 請解釋`selection sort`和 `bubble sort` 的原理及其時間複雜度(Big *O* and Big Ω)。 [答案](#Sort)

## Lecture 3(2020)

### Searching

以搜尋演算法來探討執行時間

進而談到big O 概念

> There are some common running times:
>
> - *O*(*n*^2)
> - *O*(*n* log *n*)
> - O(n)
>   - (searching one page at a time, in order)
> - O(log n)
>   - (dividing the phone book in half each time)
> - O(1)
>   - An algorithm that takes a **constant** number of steps, regardless of how big the problem is.

以及下限情況

> - Computer scientists might also use big Ω, big Omega notation, which is the lower bound of number of steps for our algorithm. Big *O* is the upper bound of number of steps, or the worst case.
> - And we have a similar set of the most common big Ω running times:
>   - Ω(*n*^2)
>   - Ω(*n* log *n*)
>   - Ω(*n*)
>   - Ω(log *n*)
>   - Ω(1)
>     - (searching in a phone book, since we might find our name on the first page we check)

#### Linear search, binary search

Linear Search

假如我們有一個未知的數列，想在其中找特定值，linear search的作法就是從Index 0開始把陣列每個位置一一確認

```C#
foreach(int num in nums)
    if (num == target)
        return true;
return false;
```

> The big *O* running time for this algorithm would be *O*(*n*), and the lower bound, big Omega, would be Ω(1).



Binary Search

同樣的問題，假如我們知道數列已經被排列過了，那我們可以透過Binary Search的演算法更有效率的找到目標

```C#
//假設mid()定義中間數
bool find(int[] nums, int target)
{
    if(nums[mid(nums.Length)] == target) {return true;}
    else if(nums.Length == 1) {return false;}
    else if(nums[mid(nums.Length)] > target)
        return find(nums.takeWhile(num => num != nums[mid(nums.Length)]), target);
    else
        return find(nums.SkipWhile(num => num != nums[mid(nums.Length)])
             .SkipWhile(num => num != nums[mid(nums.Length)]), target);
}
```

> The upper bound for binary search is *O*(log *n*), and the lower bound also Ω(1), if the number we’re looking for is in the middle, where we happen to start.



#### Searching with code

就以C實作linear search，沒啥好講的

一般來說C是無法比對string的(根本不存在的型別怎麼比對)，這邊有對這點加以說明

> We can’t compare strings directly in C, since they’re not a simple data type but rather an array of many characters. Luckily, the `string` library has a `strcmp` (“string compare”) function which compares strings for us, one character at a time, and returns `0` if they’re the same.



### Struct

基本介紹，**略**

### Sort

介紹Selection Sort 和 Bubble Sort

還有[動畫](https://www.cs.usfca.edu/~galles/visualization/ComparisonSort.html)比較，滿有趣的



> - So our upper bounds for running time that we’ve seen are:
>
>   - O(n2)
>     - selection sort, bubble sort
>   - *O*(*n* log *n*)
>   - O(n)
>     - linear search
>   - O(log n)
>     - binary search
>   - *O*(1)
>
> - 
>
>   And for lower bounds:
>
>   - Ω(n2)
>     - selection sort
>   - Ω(*n* log *n*)
>   - Ω(n)
>     - bubble sort
>   - Ω(log *n*)
>   - Ω(1)
>     - linear search, binary search

### Recursion

介紹遞迴概念 **略**

### Merge Sort

介紹Merge Sort

簡單的說就是將數列分成兩半，分別排列後再將其組合起來，可以搭配遞迴概念拆的更細

> - Each shelf required n steps, and there were only log n shelves needed, so we multiply those factors together. Our total running time for binary search is O(n log n):
>   - O(n2)
>     - selection sort, bubble sort
>   - O(n log n)
>     - merge sort
>   - O(n)
>     - linear search
>   - O(log n)
>     - binary search
>   - *O*(1)
> - (Since log *n* is greater than 1 but less than *n*, *n* log *n* is in between *n* (times 1) and *n*2.)
> - The best case, Ω, is still n log n, since we still have to sort each half first and then merge them together:
>   - Ω(n2)
>     - selection sort
>   - Ω(n log n)
>     - merge sort
>   - Ω(n)
>     - bubble sort
>   - Ω(log *n*)
>   - Ω(1)
>     - linear search, binary search
> - Even though merge sort is likely to be faster than selection sort or bubble sort, we did need another shelf, or more memory, to temporarily store our merged lists at each stage. We face the tradeoff of incurring a higher cost, another array in memory, for the benefit of faster sorting.
> - Finally, there is another notation, Θ, Theta, which we use to describe running times of algorithms if the upper bound and lower bound is the same. For example, merge sort has Θ(n log n) since the best and worst case both require the same number of steps. And selection sort has Θ(n2):
>   - Θ(n2)
>     - selection sort
>   - Θ(n log n)
>     - merge sort
>   - Θ(*n*)
>   - Θ(log *n*)
>   - Θ(1)

## Quiz 3

![](https://i.imgur.com/GRc1DAI.png)

```Ans
(a)
```

```C#
struct Person
{
    string name;
    float height;
}
Person findTallest(Person[] people)
{
    Person tallestOne = people[0];
    foreach(Person p in people)
        if(p.height > tallestOne.height)
            tallestOne = p;
    return tallestOne;
}
```

```Ans
(b) O(n)
```



![](https://i.imgur.com/wmhKf3U.png)

```Ans
(a) by using struct, you don't need to match the index of two or more arrays
(b) string relation;
	string company;
```



![](https://i.imgur.com/R3vnjaw.png)

```Ans
Whether the items have been sorted or not doesn't matter when using linear search since it always cost O(n).
Consider the time cost by sorting, it's not a good idea to sort before linear search.
If you only search once binary search is not a good choice since it doesn't work before sorting.
If you will search the items many times, binary search will be more efficiency than linear search.
```